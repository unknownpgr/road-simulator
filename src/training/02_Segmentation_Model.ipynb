{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02. Segmentation Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "13X_L86W8_tInep6zlBRsjGsJUWysqpig",
      "authorship_tag": "ABX9TyOcWXdoh2NSUcoU8Tb9usoZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7a0a2d18572410f8fc835f3cc491d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dec4793d49fe4a7082557e1c51634770",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4afc86b7b97a42d8a3673acb7f9994ad",
              "IPY_MODEL_c3bbc47e69b049108b2b9c39b6f7f026"
            ]
          }
        },
        "dec4793d49fe4a7082557e1c51634770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4afc86b7b97a42d8a3673acb7f9994ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f6b8a25851f467f94d1e4476364c486",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_539ad5cac5484d49bf646c442303492e"
          }
        },
        "c3bbc47e69b049108b2b9c39b6f7f026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07d68c3d58ce48e88d1831d601b0727a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 54.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5414a07ce0e425296511dbd3d0aa288"
          }
        },
        "3f6b8a25851f467f94d1e4476364c486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "539ad5cac5484d49bf646c442303492e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07d68c3d58ce48e88d1831d601b0727a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5414a07ce0e425296511dbd3d0aa288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unknownpgr/road-simulator/blob/master/src/training/02_Segmentation_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DarlmO5DwXor"
      },
      "source": [
        "# 02. Segmentation Model\n",
        "The goal of this script is to implement pixel segmentation model for lane detection.\n",
        "\n",
        "## Question\n",
        "I used torch.nn.BCEWithLogitsLoss for loss function. What exactly it is?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlZB15nmyhqd"
      },
      "source": [
        "## Import Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_WTxl-_6p4Q"
      },
      "source": [
        "# Platform\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Install required library\n",
        "!pip install segmentation-models-pytorch\n",
        "\n",
        "# Data preprocessing\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "# Training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3d27MJSwfJF"
      },
      "source": [
        "## Prepare Dataset\n",
        "Run this block after mounting Google Dirve.\n",
        "\n",
        "This block will remove existing files, copy dataset zip file from google drive to collab, and extract dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAGq7HXhxCa7"
      },
      "source": [
        "!rm -rf /content/dataset\n",
        "!rm /content/dataset.zip\n",
        "!cp \"/content/drive/MyDrive/[2021]Computer Vision ML/data_segmentation.zip\" /content/dataset.zip\n",
        "!unzip /content/dataset.zip -d /content/dataset\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTibU-wN3FqV"
      },
      "source": [
        "## Construct Traning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68tBNIve1XfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7a0a2d18572410f8fc835f3cc491d51",
            "dec4793d49fe4a7082557e1c51634770",
            "4afc86b7b97a42d8a3673acb7f9994ad",
            "c3bbc47e69b049108b2b9c39b6f7f026",
            "3f6b8a25851f467f94d1e4476364c486",
            "539ad5cac5484d49bf646c442303492e",
            "07d68c3d58ce48e88d1831d601b0727a",
            "e5414a07ce0e425296511dbd3d0aa288"
          ]
        },
        "outputId": "27d99709-089c-452b-8094-893228a80b42"
      },
      "source": [
        "class U_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(U_Net, self).__init__()\n",
        "\n",
        "        # Define model structure at once by using nn.ModuleList.\n",
        "        # Even though only one model is used, use nn.ModuleList for further extension.\n",
        "        self.layers = nn.ModuleList([\n",
        "                                    #  Use Unet as pixel classifier\n",
        "                                     smp.Unet(\n",
        "                                         encoder_name=\"resnet34\",        \n",
        "                                        #  encoder_weights=\"imagenet\",     \n",
        "                                         in_channels=1,                  \n",
        "                                         classes=4\n",
        "                                     )\n",
        "                                     ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Test model. Not to affect global variables, wrap it with function.\n",
        "def test():\n",
        "    model_test = U_Net()\n",
        "    print(model_test)\n",
        "test()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7a0a2d18572410f8fc835f3cc491d51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "U_Net(\n",
            "  (layers): ModuleList(\n",
            "    (0): Unet(\n",
            "      (encoder): ResNetEncoder(\n",
            "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (5): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (decoder): UnetDecoder(\n",
            "        (center): Identity()\n",
            "        (blocks): ModuleList(\n",
            "          (0): DecoderBlock(\n",
            "            (conv1): Conv2dReLU(\n",
            "              (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention1): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "            (conv2): Conv2dReLU(\n",
            "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention2): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "          )\n",
            "          (1): DecoderBlock(\n",
            "            (conv1): Conv2dReLU(\n",
            "              (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention1): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "            (conv2): Conv2dReLU(\n",
            "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention2): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "          )\n",
            "          (2): DecoderBlock(\n",
            "            (conv1): Conv2dReLU(\n",
            "              (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention1): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "            (conv2): Conv2dReLU(\n",
            "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention2): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "          )\n",
            "          (3): DecoderBlock(\n",
            "            (conv1): Conv2dReLU(\n",
            "              (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention1): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "            (conv2): Conv2dReLU(\n",
            "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention2): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "          )\n",
            "          (4): DecoderBlock(\n",
            "            (conv1): Conv2dReLU(\n",
            "              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention1): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "            (conv2): Conv2dReLU(\n",
            "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): ReLU(inplace=True)\n",
            "            )\n",
            "            (attention2): Attention(\n",
            "              (attention): Identity()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (segmentation_head): SegmentationHead(\n",
            "        (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): Identity()\n",
            "        (2): Activation(\n",
            "          (activation): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "852Az8Gqzedw"
      },
      "source": [
        "## Configure Dataset Loader\n",
        "`labels` parameter of `DatasetCustom` constructor is a dataframe of tuples `(file name, position, angle)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xRWr2gDzuub"
      },
      "source": [
        "IMAGE_INPUT_SIZE = 128\n",
        "IMAGE_LABEL_SIZE = 128\n",
        "\n",
        "class ToTensor():\n",
        "    def __call__(self,sample):\n",
        "        image, label = sample\n",
        "        # Swap color axis because axis order is:\n",
        "        # Numpy image: H, W, C\n",
        "        # Torch image: C, H, W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        label = label.transpose((2, 0, 1))\n",
        "        return (torch.FloatTensor(image), torch.FloatTensor(label))\n",
        "\n",
        "class DatasetCustom(Dataset):\n",
        "\n",
        "    def __init__(self, metadata, transforms=[ToTensor()]):\n",
        "        '''\n",
        "        There was an error when metadata columns are not wrapped with `list`.\n",
        "        By converting metadata type to list, problem solved.\n",
        "        Why?\n",
        "        '''\n",
        "        self.path_input = list(metadata['input'])\n",
        "        self.path_label = list(metadata['label'])\n",
        "        self.transforms = T.Compose(transforms)\n",
        "        self.length = len(metadata)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        path_input = self.path_input[index].replace('\\\\','/')\n",
        "        path_label = self.path_label[index].replace('\\\\','/')\n",
        "\n",
        "        # Because the input is an grayscale image, only take the first channel.\n",
        "        input = cv2.imread(path_input)[:,:,0].astype('float')/255\n",
        "        input = cv2.resize(input,(IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE))\n",
        "        input = input.reshape([IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE,1])\n",
        "        \n",
        "        # Convert ecah pixel in the label to one-hot vector.\n",
        "        label_raw = cv2.imread(path_label).astype('float')[:,:,1]\n",
        "        label_raw = cv2.resize(label_raw,(IMAGE_LABEL_SIZE, IMAGE_LABEL_SIZE))\n",
        "\n",
        "        c1 = label_raw > 200                                            # Lane\n",
        "        c2 = np.logical_and(133 > label_raw, label_raw > 123)           # Obstacle\n",
        "        c3 = label_raw < 20                                             # Ground\n",
        "        c4 = np.logical_not(np.logical_or(np.logical_or(c1, c2), c3))   # Else\n",
        "\n",
        "        label = np.zeros([IMAGE_LABEL_SIZE, IMAGE_LABEL_SIZE, 4], dtype=np.float)\n",
        "        label[:,:,0][c1] = 1\n",
        "        label[:,:,1][c2] = 1\n",
        "        label[:,:,2][c3] = 1\n",
        "        label[:,:,3][c4] = 1\n",
        "        \n",
        "        sample = (input, label)\n",
        "        sample = self.transforms(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boSNT5bcgvwY"
      },
      "source": [
        "## Define Dataset and Data Loader\n",
        "Make traning dataset and validation dataset by splitting whole label into two parts.\n",
        "\n",
        "`label.csv` is a list of tuples `(file name, position, angle)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M99S8A3ngxGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605ca309-7f05-4810-ad66-a6a78e53995f"
      },
      "source": [
        "# Define dataset\n",
        "ROOT = 'dataset'\n",
        "VALIDATION_RATIO = 0.2\n",
        "\n",
        "labels = pd.read_csv(os.path.join(ROOT, \"meta.csv\"))\n",
        "labels = sklearn.utils.shuffle(labels)\n",
        "labels = ROOT+'\\\\'+labels\n",
        "\n",
        "valid_count = int(len(labels)*VALIDATION_RATIO)\n",
        "\n",
        "train_dataset = DatasetCustom(labels[valid_count:])\n",
        "valid_dataset = DatasetCustom(labels[:valid_count])\n",
        "\n",
        "print('Train dataset:',len(train_dataset))\n",
        "print('Valid dataset:',len(valid_dataset))\n",
        "\n",
        "# Define data loaders.\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 256,\n",
        "    shuffle = True,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "valid_data_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    num_workers = 2\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset: 2923\n",
            "Valid dataset: 730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WofoJJEABzjK"
      },
      "source": [
        "## Set Traning Device\n",
        "Use GPU if possible. Else, use CPU instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF8kACVQBy-0",
        "outputId": "fc962977-8f8a-46e6-b8dd-cd923e1f1e45"
      },
      "source": [
        "is_cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if is_cuda_available else \"cpu\")\n",
        "\n",
        "if is_cuda_available:\n",
        "    print('CUDA is available and the device was set to GPU.')\n",
        "else:\n",
        "    print('CUDA is not available and the device was set to CPU.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available and the device was set to GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oIPCsyh6xTi"
      },
      "source": [
        "## Configure Traning Environment\n",
        "Traning environment configuration part and traning part are spearated so that traning can be done multiple times without reinitializing model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3MLSxMA6zLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6aaeac-a82f-4c41-cedb-9c01cf99de33"
      },
      "source": [
        "# Define  model and move it to traning device.\n",
        "model = U_Net()\n",
        "model.to(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "U_Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Unet(\n",
              "      (encoder): ResNetEncoder(\n",
              "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "        (layer1): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (2): BasicBlock(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (layer2): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (2): BasicBlock(\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (3): BasicBlock(\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (layer3): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (2): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (3): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (4): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (5): BasicBlock(\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (layer4): Sequential(\n",
              "          (0): BasicBlock(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): BasicBlock(\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (2): BasicBlock(\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (decoder): UnetDecoder(\n",
              "        (center): Identity()\n",
              "        (blocks): ModuleList(\n",
              "          (0): DecoderBlock(\n",
              "            (conv1): Conv2dReLU(\n",
              "              (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention1): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "            (conv2): Conv2dReLU(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention2): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "          )\n",
              "          (1): DecoderBlock(\n",
              "            (conv1): Conv2dReLU(\n",
              "              (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention1): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "            (conv2): Conv2dReLU(\n",
              "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention2): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "          )\n",
              "          (2): DecoderBlock(\n",
              "            (conv1): Conv2dReLU(\n",
              "              (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention1): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "            (conv2): Conv2dReLU(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention2): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "          )\n",
              "          (3): DecoderBlock(\n",
              "            (conv1): Conv2dReLU(\n",
              "              (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention1): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "            (conv2): Conv2dReLU(\n",
              "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention2): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "          )\n",
              "          (4): DecoderBlock(\n",
              "            (conv1): Conv2dReLU(\n",
              "              (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention1): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "            (conv2): Conv2dReLU(\n",
              "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "            )\n",
              "            (attention2): Attention(\n",
              "              (attention): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (segmentation_head): SegmentationHead(\n",
              "        (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Identity()\n",
              "        (2): Activation(\n",
              "          (activation): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S45S1fr-64R0"
      },
      "source": [
        "# Define optimzer.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)    \n",
        "\n",
        "# Define learning rate scheduler. It will automatically adjust learning rate.\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size = 5,\n",
        "                                               gamma = 0.75)\n",
        "\n",
        "# Define loss function.\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7bT8paOEfM1"
      },
      "source": [
        "## Train Model\n",
        "valid_loss_min should be sustained so that it is in separated block. The training part below can be run multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNUiRYPIzp58"
      },
      "source": [
        "min_loss = float('inf')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2jbVaiEg2H",
        "outputId": "ee927698-889f-46f7-9c63-851120ff62f6"
      },
      "source": [
        "try:\n",
        "    for epoch in range(1, 501):\n",
        "    \n",
        "        with tqdm(train_data_loader, unit=\"batch\") as train_bar:\n",
        "            train_bar.set_description(f\"Train Epoch {epoch}\")\n",
        "\n",
        "            # Train one epoch\n",
        "            train_loss_list = []\n",
        "            for sample in train_bar:\n",
        "\n",
        "                # For each sample(batch), initialize gradients.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Split images and labels, and move it to device.\n",
        "                images, labels = sample\n",
        "\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Set model to training mode.\n",
        "                model.train()\n",
        "\n",
        "                # Enable gradients.\n",
        "                with torch.set_grad_enabled(True):\n",
        "                    # Predict results.\n",
        "                    predicts  = model(images)\n",
        "\n",
        "                    # Calculate loss.\n",
        "                    loss = criterion(predicts, labels)\n",
        "\n",
        "                    # Update delta with back-propagation.\n",
        "                    loss.backward()\n",
        "\n",
        "                    # Training model with optimzer.\n",
        "                    optimizer.step()\n",
        "\n",
        "                # Add loss(which is just single number) to train loss list.\n",
        "                train_loss_list.append(loss.item())\n",
        "\n",
        "                # Get average of loss and display it on progress bar.\n",
        "                train_loss = np.mean(train_loss_list)\n",
        "                train_bar.set_postfix(train_loss = train_loss)\n",
        "                \n",
        "        # Adjust learning rate after training one epoch.\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Calculate validation score after training one epoch.\n",
        "        with tqdm(valid_data_loader, unit=\"batch\") as valid_bar:\n",
        "            valid_bar.set_description(f\"Valid Epoch {epoch}\")\n",
        "    \n",
        "            valid_loss_list = []\n",
        "            for sample in valid_bar:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                images, labels = sample\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Unlike traning, set model to evaluation mode and disable gradients.\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    predicts  = model(images)\n",
        "                    loss = criterion(predicts, labels)\n",
        "                    valid_loss_list.append(loss.item())\n",
        "\n",
        "                valid_loss = np.mean(valid_loss_list)\n",
        "                valid_bar.set_postfix(valid_loss = valid_loss)\n",
        "\n",
        "        valid_loss = np.mean(valid_loss_list)\n",
        "        if valid_loss < min_loss:\n",
        "            min_loss = valid_loss\n",
        "            model_name = \"unet\"\n",
        "            path = \"/content/drive/MyDrive/[2021]Computer Vision ML/\"\n",
        "            torch.save(model, f'{path}[{model_name}].pth')\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    clear_output()\n",
        "    print('Learning finished by keyboard inturrupt.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.03s/batch, train_loss=0.334]\n",
            "Valid Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.69batch/s, valid_loss=0.257]\n",
            "Train Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.05s/batch, train_loss=0.207]\n",
            "Valid Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.22batch/s, valid_loss=0.16]\n",
            "Train Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.06s/batch, train_loss=0.133]\n",
            "Valid Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.14batch/s, valid_loss=0.111]\n",
            "Train Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.08s/batch, train_loss=0.0929]\n",
            "Valid Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.26batch/s, valid_loss=0.087]\n",
            "Train Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:13<00:00,  1.10s/batch, train_loss=0.073]\n",
            "Valid Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.22batch/s, valid_loss=0.0709]\n",
            "Train Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:13<00:00,  1.11s/batch, train_loss=0.0622]\n",
            "Valid Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.27batch/s, valid_loss=0.0607]\n",
            "Train Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:13<00:00,  1.09s/batch, train_loss=0.0544]\n",
            "Valid Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.95batch/s, valid_loss=0.053]\n",
            "Train Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.08s/batch, train_loss=0.0484]\n",
            "Valid Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.19batch/s, valid_loss=0.0478]\n",
            "Train Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:12<00:00,  1.08s/batch, train_loss=0.0438]\n",
            "Valid Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 16.23batch/s, valid_loss=0.0459]\n",
            "Train Epoch 10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:11<00:02,  1.11s/batch, train_loss=0.0407]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYZKmr2DGRdz"
      },
      "source": [
        "## Test Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svr6-OKaGcks"
      },
      "source": [
        "def to_rgb(array):\n",
        "    array = np.swapaxes(array,0,1)\n",
        "    array = np.swapaxes(array,1,2)\n",
        "    array = array[:,:,0:3]\n",
        "    array[array<0]=0\n",
        "    array[array>1]=1\n",
        "    return array\n",
        "\n",
        "def test_model():\n",
        "    # Get sample data\n",
        "    index, sample = next(enumerate(valid_data_loader))\n",
        "    images, labels = sample\n",
        "\n",
        "    # Move it to device\n",
        "    images = images.to(device)\n",
        "\n",
        "    # Predict\n",
        "    optimizer.zero_grad()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicts = model(images)\n",
        "\n",
        "    # Get images, labels and prediction results to cpu, and convert them to numpy array.\n",
        "    images = images.cpu().detach().numpy()\n",
        "    predicts = predicts.cpu().detach().numpy()\n",
        "\n",
        "    # Check value range\n",
        "    print(np.max(images),np.max(predicts),np.max(labels.numpy()))\n",
        "    print(np.min(images),np.min(predicts),np.min(labels.numpy()))\n",
        "\n",
        "    # For each cases,\n",
        "    for i in range(min(len(labels),20)):\n",
        "        \n",
        "        f, axarr = plt.subplots(1,4) \n",
        "\n",
        "        # Display image\n",
        "        axarr[0].imshow(images[i][0])\n",
        "        axarr[0].title.set_text(f\"Input {i+1}\")\n",
        "        axarr[0].axis('off')\n",
        "\n",
        "        axarr[1].imshow(to_rgb(predicts[i]))\n",
        "        axarr[1].title.set_text(f\"Prediction {i+1}\")\n",
        "        axarr[1].axis('off')\n",
        "        \n",
        "        axarr[2].imshow(to_rgb(labels[i]))\n",
        "        axarr[2].title.set_text(f\"Label {i+1}\")\n",
        "        axarr[2].axis('off')\n",
        "\n",
        "        axarr[3].imshow(to_rgb(np.abs(predicts[i]-labels[i].numpy())))\n",
        "        axarr[3].title.set_text(f\"Error {i+1}\")\n",
        "        axarr[3].axis('off')\n",
        "\n",
        "test_model()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}